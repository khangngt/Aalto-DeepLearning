{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Reshape, Permute\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Architecture of CRNN model\n",
    "\n",
    "# Pre-setting\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    input_shape = (1, 96, 1366)\n",
    "    channel_axis = 1\n",
    "    freq_axis  = 2\n",
    "    time_axis = 3\n",
    "    print('K.image_dim_ordering is th')\n",
    "else:\n",
    "    # K.image_dim_ordering() == 'tf'\n",
    "    K.set_image_dim_ordering('th')\n",
    "    input_shape = (1, 96, 1366)\n",
    "    channel_axis = 1\n",
    "    freq_axis  = 2\n",
    "    time_axis = 3\n",
    "    print('K.image_dim_ordering has been changed to {}'.format(K.image_dim_ordering()))\n",
    "\n",
    "# Input\n",
    "melgram_inputs = Input(shape=input_shape)\n",
    "x = ZeroPadding2D(padding=(0, 37))(melgram_inputs)\n",
    "print('x.shape={}'.format(x.shape)) # (?, 1, 96, 1440)\n",
    "x = BatchNormalization(axis=freq_axis, name='bn_0_freq')(x)\n",
    "print('x.shape={}'.format(x.shape)) # (?, 1, 96, 1440)\n",
    "\n",
    "# Convolution layer 1\n",
    "x = Convolution2D(64, 3, 3, border_mode='same', name='conv1')(x)\n",
    "x = BatchNormalization(axis=channel_axis, mode=0, name='bn1')(x)\n",
    "x = ELU()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool1')(x)\n",
    "x = Dropout(0.1, name='dropout1')(x)\n",
    "print('x.shape={}'.format(x.shape)) # (?, 64, 48, 720)\n",
    "\n",
    "# Convolution layer 2\n",
    "x = Convolution2D(128, 3, 3, border_mode='same', name='conv2')(x)\n",
    "x = BatchNormalization(axis=channel_axis, mode=0, name='bn2')(x)\n",
    "x = ELU()(x)\n",
    "x = MaxPooling2D(pool_size=(3, 3), strides=(3, 3), name='pool2')(x)\n",
    "x = Dropout(0.1, name='dropout2')(x)\n",
    "print('x.shape={}'.format(x.shape)) # (?, 128, 16, 240)\n",
    "\n",
    "# Convolution layer 3\n",
    "x = Convolution2D(128, 3, 3, border_mode='same', name='conv3')(x)\n",
    "x = BatchNormalization(axis=channel_axis, mode=0, name='bn3')(x)\n",
    "x = ELU()(x)\n",
    "x = MaxPooling2D(pool_size=(4, 4), strides=(4, 4), name='pool3')(x)\n",
    "x = Dropout(0.1, name='dropout3')(x)\n",
    "print('x.shape={}'.format(x.shape)) # (?, 128, 4, 60)\n",
    "\n",
    "# Convolution layer 4\n",
    "x = Convolution2D(128, 3, 3, border_mode='same', name='conv4')(x)\n",
    "x = BatchNormalization(axis=channel_axis, mode=0, name='bn4')(x)\n",
    "x = ELU()(x)\n",
    "x = MaxPooling2D(pool_size=(4, 4), strides=(4, 4), name='pool4')(x)\n",
    "x = Dropout(0.1, name='dropout4')(x)\n",
    "print('x.shape={}'.format(x.shape)) # (?, 128, 1, 15)\n",
    "\n",
    "# Reshaping the output of CNN for the input of RNN\n",
    "x = Permute((3, 1, 2))(x) # original output of CNN: 128x1x15\n",
    "print('x.shape={}'.format(x.shape)) # (?, 15, 128, 1)\n",
    "x = Reshape((15, 128))(x)\n",
    "print('x.shape={}'.format(x.shape)) # (?, 15, 128)\n",
    "\n",
    "# 2-layers RNN\n",
    "x = GRU(output_dim=32, return_sequences=True, name='gru1')(x)\n",
    "print('x.shape={}'.format(x.shape)) # =(?, 15, 32)\n",
    "x = GRU(32, return_sequences=False, name='gru2')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "print('x.shape={}'.format(x.shape)) # =(?, 32)\n",
    "\n",
    "# Fully-connected layer (output layer)\n",
    "predictions = Dense(50, activation='sigmoid', name='output')(x)\n",
    "print('predictions.shape={}'.format(predictions.shape)) # =(?, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC-ROC as the evaluation index\n",
    "\n",
    "def AUC_ROC(y_true, y_pred):  \n",
    "    tprs = tf.stack([binary_TPR(y_true, y_pred, k) for k in np.linspace(0, 1, 100)], axis=0)  \n",
    "    fprs = tf.stack([binary_FPR(y_true, y_pred, k) for k in np.linspace(0, 1, 100)], axis=0)  \n",
    "    fprs = tf.concat([tf.ones((1,)) , fprs], axis=0)\n",
    "    binSizes = -(fprs[1:]-fprs[:-1])\n",
    "    s = tprs*binSizes\n",
    "    return K.sum(s, axis=0)\n",
    "\n",
    "def binary_FPR(y_true, y_pred, threshold=K.variable(value=0.5)):  \n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')  \n",
    "    N = K.sum(1 - y_true) # N = Condition negative = FP+TN\n",
    "    FP = K.sum(y_pred - y_pred * y_true)  \n",
    "    return FP/N\n",
    "\n",
    "def binary_TPR(y_true, y_pred, threshold=K.variable(value=0.5)):  \n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')  \n",
    "    P = K.sum(y_true) # P = Condition positive = TP+FN\n",
    "    TP = K.sum(y_pred * y_true)  \n",
    "    return TP/P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "model = Model(input=melgram_inputs, output=predictions)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', AUC_ROC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "X_train = np.load('D:/sets/train_x.npy')\n",
    "y_train = np.load('D:/sets/train_y.npy')\n",
    "print('X_train.shape={}, y_train.shape={}'.format(X_train.shape, y_train.shape))\n",
    "\n",
    "X_valid = np.load('D:/sets/valid_x.npy')\n",
    "y_valid = np.load('D:/sets/valid_y.npy')\n",
    "print('X_valid.shape={}, y_valid.shape={}'.format(X_valid.shape,y_valid.shape))\n",
    "\n",
    "X_test = np.load('D:/sets/test_x.npy')\n",
    "y_test = np.load('D:/sets/test_y.npy')\n",
    "print('X_valid.shape={}, y_valid.shape={}'.format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=16, nb_epoch=40, verbose=1, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "\n",
    "test_result = model.evaluate(X_test, y_test, batch_size=16)\n",
    "print('Loss in test set', test_result[0])\n",
    "print('Accuracy in test set', test_result[1])\n",
    "print('AUC-ROC in test set', test_result[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
